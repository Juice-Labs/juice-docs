"use strict";(self.webpackChunkjuice_docs=self.webpackChunkjuice_docs||[]).push([[7516],{3488:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>t,contentTitle:()=>a,default:()=>u,frontMatter:()=>r,metadata:()=>l,toc:()=>d});const l=JSON.parse('{"id":"juice/pro-users/running-applications/ollama","title":"Ollama","description":"When Ollama installs it starts the server locally by default. To run your workload, stop the local server and restart it once the juice session is created.","source":"@site/docs/juice/pro-users/running-applications/ollama.md","sourceDirName":"juice/pro-users/running-applications","slug":"/juice/pro-users/running-applications/ollama","permalink":"/juice-docs/docs/juice/pro-users/running-applications/ollama","draft":false,"unlisted":false,"editUrl":"https://github.com/juice-labs/juice-docs/edit/master/docs/juice/pro-users/running-applications/ollama.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"title":"Ollama","sidebar_position":3},"sidebar":"tutorialSidebar","previous":{"title":"Jupyterlab","permalink":"/juice-docs/docs/juice/pro-users/running-applications/jupyterlab"},"next":{"title":"Examples","permalink":"/juice-docs/docs/juice/pro-users/running-applications/examples"}}');var s=i(4848),o=i(8453);const r={title:"Ollama",sidebar_position:3},a="Ollama",t={},d=[{value:"Installation",id:"installation",level:2},{value:"Running Ollama with Juice from the CLI App (Linux, Windows, WSL)",id:"running-ollama-with-juice-from-the-cli-app-linux-windows-wsl",level:3},{value:"With a single GPU:",id:"with-a-single-gpu",level:4},{value:"With multiple GPUs:",id:"with-multiple-gpus",level:4},{value:"Additional Considerations",id:"additional-considerations",level:4},{value:"LLAMA.cpp",id:"llamacpp",level:2},{value:"GPT4all",id:"gpt4all",level:2},{value:"ComfyUI",id:"comfyui",level:2},{value:"Visual Studio Code (VSCode)",id:"visual-studio-code-vscode",level:2},{value:"To use Visual Studio Code with a remote GPU in Juice:",id:"to-use-visual-studio-code-with-a-remote-gpu-in-juice",level:4},{value:"Troubleshooting",id:"troubleshooting",level:3}];function c(e){const n={a:"a",admonition:"admonition",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"ollama",children:"Ollama"})}),"\n",(0,s.jsx)(n.p,{children:"When Ollama installs it starts the server locally by default. To run your workload, stop the local server and restart it once the juice session is created."}),"\n",(0,s.jsx)(n.h2,{id:"installation",children:"Installation"}),"\n",(0,s.jsxs)(n.p,{children:["Follow the instructions on the ",(0,s.jsx)(n.a,{href:"https://github.com/ollama/ollama",children:"Ollama GitHub page"})," to install Ollama. The default installation paths for Ollama are:"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Windows"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"C:\\Users[user]\\AppData\\Local\\Programs\\Ollama"}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"C:\\Users[user].ollama (Models)"}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h3,{id:"running-ollama-with-juice-from-the-cli-app-linux-windows-wsl",children:"Running Ollama with Juice from the CLI App (Linux, Windows, WSL)"}),"\n",(0,s.jsx)(n.h4,{id:"with-a-single-gpu",children:"With a single GPU:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-powershell",children:"juice run ollama run <your_parameters>\n"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Example:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-powershell",children:'juice run ollama run --model mistral-7b-instruct --prompt "What is quantum physics?"\n'})}),"\n",(0,s.jsx)(n.h4,{id:"with-multiple-gpus",children:"With multiple GPUs:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-powershell",children:"juice run --num-gpus <number_of_gpus> ollama run <your_parameters>\n"})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Example"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-powershell",children:'juice run --num-gpus 2 ollama run --model mistral-7b-instruct --prompt "What is quantum physics?" \n'})}),"\n",(0,s.jsx)(n.admonition,{type:"note",children:(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Replace <number_of_gpus> and <gpu_uuid> with the desired values."}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"You can find available GPU IDs using the juice gpu list command."}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Ensure that Ollama\u2019s server is not running prior to launching with Juice. If it fails to leverage a remote GPU, try exiting the server and relaunching Ollama with the instructions above."}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Ensure the specified GPUs are available and part of your pool."}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["Refer to the ",(0,s.jsx)(n.a,{href:"/juice-docs/docs/juice/pro-users/cli-app/",children:"Juice CLI documentation"})," for more advanced run options."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"On Windows, be sure to add both the Ollama program path, as well as the models folder to your path."}),"\n"]}),"\n"]})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h4,{id:"additional-considerations",children:"Additional Considerations"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Model Download"}),": Ollama models are downloaded separately. Ensure you have downloaded the desired models before running them."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Resource Requirements"}),": Large language models can be resource-intensive. Make sure the selected GPUs have sufficient VRAM and processing power for your chosen model."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["This documentation should help get you started. For advanced usage and troubleshooting, please refer to the official ",(0,s.jsx)(n.a,{href:"https://github.com/ollama/ollama?tab=readme-ov-file",children:"Ollama"})," and ",(0,s.jsx)(n.a,{href:"https://juicelabs.co/docs",children:"Juice documentation"}),"."]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"llamacpp",children:"LLAMA.cpp"}),"\n",(0,s.jsx)(n.p,{children:"We support llama.cpp when built with CUDA."}),"\n",(0,s.jsx)(n.p,{children:"Ensure you have the correct version built (I.e. CUDA is activated), then run it like you would any other application with Juice."}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"gpt4all",children:"GPT4all"}),"\n",(0,s.jsx)(n.p,{children:"We support GPT4all similar to any other application. Run the application with the CLI:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-powershell",children:"juice run gpt4all.exe\n"})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"comfyui",children:"ComfyUI"}),"\n",(0,s.jsx)(n.p,{children:"ComfyUI is supported, but must be run with the following command line argument for optimal performance:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-powershell",children:"--disable-cuda-malloc \n"})}),"\n",(0,s.jsxs)(n.p,{children:["Edit ",(0,s.jsx)(n.em,{children:(0,s.jsx)(n.strong,{children:"run_nvidia-gpu.bat"})})," and add the command above to the command line, or launch with that command line directly:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-powershell",children:".\\python_embeded\\python.exe -s ComfyUI\\main.py\n--windows-standalone-build --disable-cuda-malloc\n"})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"visual-studio-code-vscode",children:"Visual Studio Code (VSCode)"}),"\n",(0,s.jsx)(n.h4,{id:"to-use-visual-studio-code-with-a-remote-gpu-in-juice",children:"To use Visual Studio Code with a remote GPU in Juice:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Locate your VSCode executable:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"On Windows"}),": Typically found at %localappdata%\\Programs\\Microsoft VS Code\\Code.exe"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"On Linux"}),": Usually /usr/bin/code or /usr/local/bin/code"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Add the VSCode executable path to Juice:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Add the path to your VSCode executable to your environment."}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Connect to a remote GPU session in Juice."}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Launch VSCode through Juice or directly if it's already configured."}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Use VSCode normally - the integrated terminal and extensions will now utilize the remote GPU."}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.admonition,{type:"note",children:(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Ensure you add the VSCode executable to Juice before launching the editor."}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"All applications run from the VSCode terminal will use the remote GPU."}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"VSCode extensions that leverage GPU acceleration will also use the remote GPU."}),"\n"]}),"\n"]})}),"\n",(0,s.jsx)(n.p,{children:"This setup allows you to develop and run GPU-accelerated code directly within VSCode, benefiting from the power of the remote GPU for tasks such as machine learning model training, data processing, or GPU-accelerated visualizations."}),"\n",(0,s.jsx)(n.h3,{id:"troubleshooting",children:"Troubleshooting"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"While VSCode is running, your GPU session might timeout if the GPU is not in use, so make sure to start running your workload immediately."}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Once your session times out, VSCode will not be able to access your local GPU until you restart it."}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Make sure to close all instances of VSCode before you connect to a Remote GPU with the CLI."}),"\n"]}),"\n"]})]})}function u(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(c,{...e})}):c(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>r,x:()=>a});var l=i(6540);const s={},o=l.createContext(s);function r(e){const n=l.useContext(o);return l.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:r(e.components),l.createElement(o.Provider,{value:n},e.children)}}}]);